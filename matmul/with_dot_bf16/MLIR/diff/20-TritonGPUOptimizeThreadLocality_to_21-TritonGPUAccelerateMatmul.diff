--- matmul/with_dot_bf16/MLIR/20-TritonGPUOptimizeThreadLocality.mlir
+++ matmul/with_dot_bf16/MLIR/21-TritonGPUAccelerateMatmul.mlir
@@ -3,6 +3,7 @@
 #blocked1 = #ttg.blocked<{sizePerThread = [4, 4], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
 #blocked2 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
 #loc = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0)
+#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
 module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:86", "ttg.threads-per-warp" = 32 : i32} {
   tt.func public @matrix_multiplication_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg1: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg5: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg6: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0)) attributes {noinline = false} {
     %cst = arith.constant dense<0.000000e+00> : tensor<64x64xbf16, #blocked> loc(#loc1)
@@ -73,8 +74,12 @@
       %72 = tt.load %70, %71, %cst : tensor<64x64x!tt.ptr<bf16>, #blocked> loc(#loc32)
       %73 = ttg.convert_layout %65 : tensor<128x64xbf16, #blocked> -> tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked1}>> loc(#loc28)
       %74 = ttg.convert_layout %72 : tensor<64x64xbf16, #blocked> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked1}>> loc(#loc32)
-      %75 = tt.dot %73, %74, %arg10, inputPrecision = tf32 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked1}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked1}>> -> tensor<128x64xf32, #blocked1> loc(#loc33)
-      scf.yield %75 : tensor<128x64xf32, #blocked1> loc(#loc34)
+      %75 = ttg.convert_layout %arg10 : tensor<128x64xf32, #blocked1> -> tensor<128x64xf32, #mma> loc(#loc1)
+      %76 = ttg.convert_layout %73 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked1}>> -> tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc28)
+      %77 = ttg.convert_layout %74 : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked1}>> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc32)
+      %78 = tt.dot %76, %77, %75, inputPrecision = tf32 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<128x64xf32, #mma> loc(#loc33)
+      %79 = ttg.convert_layout %78 : tensor<128x64xf32, #mma> -> tensor<128x64xf32, #blocked1> loc(#loc33)
+      scf.yield %79 : tensor<128x64xf32, #blocked1> loc(#loc34)
     } loc(#loc23)
     %43 = tt.splat %arg8 : i32 -> tensor<128x1xi32, #blocked2> loc(#loc35)
     %44 = arith.muli %17, %43 : tensor<128x1xi32, #blocked2> loc(#loc35)
