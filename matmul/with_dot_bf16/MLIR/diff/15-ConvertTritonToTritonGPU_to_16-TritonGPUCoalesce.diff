--- matmul/with_dot_bf16/MLIR/15-ConvertTritonToTritonGPU.mlir
+++ matmul/with_dot_bf16/MLIR/16-TritonGPUCoalesce.mlir
@@ -4,7 +4,9 @@
 #blocked2 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
 #blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
 #blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
-#blocked5 = #ttg.blocked<{sizePerThread = [4, 4], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
+#blocked5 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
+#blocked6 = #ttg.blocked<{sizePerThread = [4, 4], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
+#blocked7 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
 #loc = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0)
 module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:86", "ttg.threads-per-warp" = 32 : i32} {
   tt.func public @matrix_multiplication_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg1: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg5: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg6: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0)) attributes {noinline = false} {
@@ -57,28 +59,36 @@
     %38 = arith.addi %arg5, %c63_i32 : i32 loc(#loc44)
     %39 = arith.divsi %38, %c64_i32 : i32 loc(#loc45)
     %40 = scf.for %arg9 = %c0_i32 to %39 step %c1_i32 iter_args(%arg10 = %cst_1) -> (tensor<128x64xf32, #blocked>)  : i32 {
-      %57 = arith.muli %arg9, %c64_i32 : i32 loc(#loc24)
-      %58 = arith.subi %arg5, %57 : i32 loc(#loc25)
-      %59 = tt.splat %58 : i32 -> tensor<1x64xi32, #blocked> loc(#loc26)
-      %60 = arith.cmpi slt, %19, %59 : tensor<1x64xi32, #blocked> loc(#loc26)
-      %61 = tt.splat %57 : i32 -> tensor<128x64xi32, #blocked> loc(#loc27)
-      %62 = tt.addptr %23, %61 : tensor<128x64x!tt.ptr<bf16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc27)
-      %63 = tt.broadcast %60 : tensor<1x64xi1, #blocked> -> tensor<128x64xi1, #blocked> loc(#loc28)
-      %64 = tt.load %62, %63, %cst_0 : tensor<128x64x!tt.ptr<bf16>, #blocked> loc(#loc28)
-      %65 = tt.splat %58 : i32 -> tensor<64x1xi32, #blocked3> loc(#loc29)
-      %66 = arith.cmpi slt, %26, %65 : tensor<64x1xi32, #blocked3> loc(#loc29)
-      %67 = arith.muli %57, %arg7 : i32 loc(#loc30)
-      %68 = tt.splat %67 : i32 -> tensor<64x64xi32, #blocked> loc(#loc31)
-      %69 = tt.addptr %37, %68 : tensor<64x64x!tt.ptr<bf16>, #blocked>, tensor<64x64xi32, #blocked> loc(#loc31)
-      %70 = tt.broadcast %66 : tensor<64x1xi1, #blocked3> -> tensor<64x64xi1, #blocked3> loc(#loc32)
-      %71 = ttg.convert_layout %70 : tensor<64x64xi1, #blocked3> -> tensor<64x64xi1, #blocked> loc(#loc32)
-      %72 = tt.load %69, %71, %cst : tensor<64x64x!tt.ptr<bf16>, #blocked> loc(#loc32)
-      %73 = ttg.convert_layout %64 : tensor<128x64xbf16, #blocked> -> tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked5}>> loc(#loc28)
-      %74 = ttg.convert_layout %72 : tensor<64x64xbf16, #blocked> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked5}>> loc(#loc32)
-      %75 = ttg.convert_layout %arg10 : tensor<128x64xf32, #blocked> -> tensor<128x64xf32, #blocked5> loc(#loc33)
-      %76 = tt.dot %73, %74, %75, inputPrecision = tf32 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked5}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked5}>> -> tensor<128x64xf32, #blocked5> loc(#loc34)
-      %77 = ttg.convert_layout %76 : tensor<128x64xf32, #blocked5> -> tensor<128x64xf32, #blocked> loc(#loc35)
-      scf.yield %77 : tensor<128x64xf32, #blocked> loc(#loc35)
+      %60 = arith.muli %arg9, %c64_i32 : i32 loc(#loc24)
+      %61 = arith.subi %arg5, %60 : i32 loc(#loc25)
+      %62 = tt.splat %61 : i32 -> tensor<1x64xi32, #blocked> loc(#loc26)
+      %63 = arith.cmpi slt, %19, %62 : tensor<1x64xi32, #blocked> loc(#loc26)
+      %64 = tt.splat %60 : i32 -> tensor<128x64xi32, #blocked> loc(#loc27)
+      %65 = tt.addptr %23, %64 : tensor<128x64x!tt.ptr<bf16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc27)
+      %66 = tt.broadcast %63 : tensor<1x64xi1, #blocked> -> tensor<128x64xi1, #blocked> loc(#loc28)
+      %67 = ttg.convert_layout %65 : tensor<128x64x!tt.ptr<bf16>, #blocked> -> tensor<128x64x!tt.ptr<bf16>, #blocked5> loc(#loc28)
+      %68 = ttg.convert_layout %66 : tensor<128x64xi1, #blocked> -> tensor<128x64xi1, #blocked5> loc(#loc28)
+      %69 = ttg.convert_layout %cst_0 : tensor<128x64xbf16, #blocked> -> tensor<128x64xbf16, #blocked5> loc(#loc28)
+      %70 = tt.load %67, %68, %69 : tensor<128x64x!tt.ptr<bf16>, #blocked5> loc(#loc28)
+      %71 = ttg.convert_layout %70 : tensor<128x64xbf16, #blocked5> -> tensor<128x64xbf16, #blocked> loc(#loc28)
+      %72 = tt.splat %61 : i32 -> tensor<64x1xi32, #blocked3> loc(#loc29)
+      %73 = arith.cmpi slt, %26, %72 : tensor<64x1xi32, #blocked3> loc(#loc29)
+      %74 = arith.muli %60, %arg7 : i32 loc(#loc30)
+      %75 = tt.splat %74 : i32 -> tensor<64x64xi32, #blocked> loc(#loc31)
+      %76 = tt.addptr %37, %75 : tensor<64x64x!tt.ptr<bf16>, #blocked>, tensor<64x64xi32, #blocked> loc(#loc31)
+      %77 = tt.broadcast %73 : tensor<64x1xi1, #blocked3> -> tensor<64x64xi1, #blocked3> loc(#loc32)
+      %78 = ttg.convert_layout %77 : tensor<64x64xi1, #blocked3> -> tensor<64x64xi1, #blocked> loc(#loc32)
+      %79 = ttg.convert_layout %76 : tensor<64x64x!tt.ptr<bf16>, #blocked> -> tensor<64x64x!tt.ptr<bf16>, #blocked5> loc(#loc32)
+      %80 = ttg.convert_layout %78 : tensor<64x64xi1, #blocked> -> tensor<64x64xi1, #blocked5> loc(#loc32)
+      %81 = ttg.convert_layout %cst : tensor<64x64xbf16, #blocked> -> tensor<64x64xbf16, #blocked5> loc(#loc32)
+      %82 = tt.load %79, %80, %81 : tensor<64x64x!tt.ptr<bf16>, #blocked5> loc(#loc32)
+      %83 = ttg.convert_layout %82 : tensor<64x64xbf16, #blocked5> -> tensor<64x64xbf16, #blocked> loc(#loc32)
+      %84 = ttg.convert_layout %71 : tensor<128x64xbf16, #blocked> -> tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked6}>> loc(#loc28)
+      %85 = ttg.convert_layout %83 : tensor<64x64xbf16, #blocked> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked6}>> loc(#loc32)
+      %86 = ttg.convert_layout %arg10 : tensor<128x64xf32, #blocked> -> tensor<128x64xf32, #blocked6> loc(#loc33)
+      %87 = tt.dot %84, %85, %86, inputPrecision = tf32 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked6}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked6}>> -> tensor<128x64xf32, #blocked6> loc(#loc34)
+      %88 = ttg.convert_layout %87 : tensor<128x64xf32, #blocked6> -> tensor<128x64xf32, #blocked> loc(#loc35)
+      scf.yield %88 : tensor<128x64xf32, #blocked> loc(#loc35)
     } loc(#loc23)
     %41 = tt.splat %arg8 : i32 -> tensor<128x1xi32, #blocked3> loc(#loc36)
     %42 = arith.muli %12, %41 : tensor<128x1xi32, #blocked3> loc(#loc36)
@@ -96,7 +106,10 @@
     %54 = ttg.convert_layout %53 : tensor<128x64xi1, #blocked3> -> tensor<128x64xi1, #blocked> loc(#loc41)
     %55 = tt.broadcast %52 : tensor<1x64xi1, #blocked> -> tensor<128x64xi1, #blocked> loc(#loc41)
     %56 = arith.andi %54, %55 : tensor<128x64xi1, #blocked> loc(#loc41)
-    tt.store %48, %40, %56 : tensor<128x64x!tt.ptr<f32>, #blocked> loc(#loc42)
+    %57 = ttg.convert_layout %48 : tensor<128x64x!tt.ptr<f32>, #blocked> -> tensor<128x64x!tt.ptr<f32>, #blocked7> loc(#loc42)
+    %58 = ttg.convert_layout %40 : tensor<128x64xf32, #blocked> -> tensor<128x64xf32, #blocked7> loc(#loc42)
+    %59 = ttg.convert_layout %56 : tensor<128x64xi1, #blocked> -> tensor<128x64xi1, #blocked7> loc(#loc42)
+    tt.store %57, %58, %59 : tensor<128x64x!tt.ptr<f32>, #blocked7> loc(#loc42)
     tt.return loc(#loc43)
   } loc(#loc)
 } loc(#loc)
