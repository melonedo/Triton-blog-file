--- matmul/with_dot_bf16/MLIR/53-TritonGPUAllocateWarpGroups.mlir
+++ matmul/with_dot_bf16/MLIR/54-SCFToControlFlowPass.mlir
@@ -2,6 +2,10 @@
 #blocked = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
 #blocked1 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
 #loc = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":6:0)
+#loc1 = loc(unknown)
+#loc23 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":35:20)
+#loc24 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":36:20)
+#loc25 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":32:22)
 #mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
 #shared = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 8, order = [1, 0]}>
 #smem = #ttg.shared_memory
@@ -98,70 +102,74 @@
     %77 = arith.andi %76, %74 : tensor<64x64xi1, #blocked> loc(#loc25)
     %78 = ttg.async_copy_global_to_local %73, %75 mask %77 other %cst_1 : tensor<64x64x!tt.ptr<bf16>, #blocked> -> <64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
     %79 = ttg.async_commit_group %78 loc(#loc24)
-    %80:7 = scf.for %arg9 = %c0_i32 to %38 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %c1_i32, %arg12 = %c-1_i32, %arg13 = %49, %arg14 = %68, %arg15 = %57, %arg16 = %79) -> (tensor<128x64xf32, #mma>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
-      %97 = arith.subi %38, %c2_i32 : i32 loc(#loc25)
-      %98 = arith.cmpi slt, %arg9, %97 : i32 loc(#loc25)
-      %99 = arith.addi %arg12, %c1_i32 : i32 loc(#loc25)
-      %100 = arith.cmpi sge, %99, %c2_i32 : i32 loc(#loc25)
-      %101 = arith.select %100, %c0_i32, %99 : i32 loc(#loc25)
-      %102 = ttg.async_wait %arg13, %arg15 {num = 2 : i32} loc(#loc23)
-      %103 = ttg.memdesc_subview %39[%101, %c0_i32, %c0_i32] : !ttg.memdesc<2x128x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xbf16, #shared, #smem, mutable, 2x128x64> loc(#loc23)
-      %104 = ttg.local_load %103 token %102 : !ttg.memdesc<128x64xbf16, #shared, #smem, mutable, 2x128x64> -> tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc23)
-      %105 = ttg.memdesc_subview %40[%101, %c0_i32, %c0_i32] : !ttg.memdesc<2x64x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
-      %106 = ttg.local_load %105 token %102 : !ttg.memdesc<64x64xbf16, #shared, #smem, mutable, 2x64x64> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc24)
-      %107 = tt.dot %104, %106, %arg10, inputPrecision = tf32 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<128x64xf32, #mma> loc(#loc32)
-      %108 = arith.addi %arg11, %c1_i32 : i32 loc(#loc25)
-      %109 = arith.cmpi sge, %108, %c2_i32 : i32 loc(#loc25)
-      %110 = arith.select %109, %c0_i32, %108 : i32 loc(#loc25)
-      %111 = arith.addi %arg9, %c2_i32 : i32 loc(#loc25)
-      %112 = arith.muli %111, %c64_i32 : i32 loc(#loc33)
-      %113 = arith.subi %arg5, %112 : i32 loc(#loc28)
-      %114 = tt.splat %113 : i32 -> tensor<1x64xi32, #blocked> loc(#loc26)
-      %115 = arith.cmpi slt, %22, %114 : tensor<1x64xi32, #blocked> loc(#loc26)
-      %116 = tt.splat %112 : i32 -> tensor<128x64xi32, #blocked> loc(#loc29)
-      %117 = tt.addptr %25, %116 : tensor<128x64x!tt.ptr<bf16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc29)
-      %118 = tt.broadcast %115 : tensor<1x64xi1, #blocked> -> tensor<128x64xi1, #blocked> loc(#loc23)
-      %119 = ttg.memdesc_subview %39[%110, %c0_i32, %c0_i32] : !ttg.memdesc<2x128x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xbf16, #shared, #smem, mutable, 2x128x64> loc(#loc23)
-      %120 = tt.splat %98 : i1 -> tensor<128x64xi1, #blocked> loc(#loc25)
-      %121 = arith.andi %120, %118 : tensor<128x64xi1, #blocked> loc(#loc25)
-      %122 = ttg.async_copy_global_to_local %117, %119 mask %121 other %cst_0 : tensor<128x64x!tt.ptr<bf16>, #blocked> -> <128x64xbf16, #shared, #smem, mutable, 2x128x64> loc(#loc23)
-      %123 = ttg.async_commit_group %122 loc(#loc23)
-      %124 = tt.splat %113 : i32 -> tensor<64x1xi32, #blocked> loc(#loc27)
-      %125 = arith.cmpi slt, %27, %124 : tensor<64x1xi32, #blocked> loc(#loc27)
-      %126 = arith.muli %112, %arg7 : i32 loc(#loc30)
-      %127 = tt.splat %126 : i32 -> tensor<64x64xi32, #blocked> loc(#loc31)
-      %128 = tt.addptr %36, %127 : tensor<64x64x!tt.ptr<bf16>, #blocked>, tensor<64x64xi32, #blocked> loc(#loc31)
-      %129 = tt.broadcast %125 : tensor<64x1xi1, #blocked> -> tensor<64x64xi1, #blocked> loc(#loc24)
-      %130 = ttg.memdesc_subview %40[%110, %c0_i32, %c0_i32] : !ttg.memdesc<2x64x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
-      %131 = tt.splat %98 : i1 -> tensor<64x64xi1, #blocked> loc(#loc25)
-      %132 = arith.andi %131, %129 : tensor<64x64xi1, #blocked> loc(#loc25)
-      %133 = ttg.async_copy_global_to_local %128, %130 mask %132 other %cst_1 : tensor<64x64x!tt.ptr<bf16>, #blocked> -> <64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
-      %134 = ttg.async_commit_group %133 loc(#loc24)
-      scf.yield %107, %110, %101, %arg14, %123, %arg16, %134 : tensor<128x64xf32, #mma>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token loc(#loc25)
-    } loc(#loc25)
-    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc25)
+    cf.br ^bb1(%c0_i32, %cst, %c1_i32, %c-1_i32, %49, %68, %57, %79 : i32, tensor<128x64xf32, #mma>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token) loc(#loc25)
+  ^bb1(%80: i32 loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":32:22), %81: tensor<128x64xf32, #mma> loc(unknown), %82: i32 loc(unknown), %83: i32 loc(unknown), %84: !ttg.async.token loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":35:20), %85: !ttg.async.token loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":35:20), %86: !ttg.async.token loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":36:20), %87: !ttg.async.token loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":36:20)):  // 2 preds: ^bb0, ^bb2
+    %88 = arith.cmpi slt, %80, %38 : i32 loc(#loc25)
+    cf.cond_br %88, ^bb2, ^bb3 loc(#loc25)
+  ^bb2:  // pred: ^bb1
+    %89 = arith.subi %38, %c2_i32 : i32 loc(#loc25)
+    %90 = arith.cmpi slt, %80, %89 : i32 loc(#loc25)
+    %91 = arith.addi %83, %c1_i32 : i32 loc(#loc25)
+    %92 = arith.cmpi sge, %91, %c2_i32 : i32 loc(#loc25)
+    %93 = arith.select %92, %c0_i32, %91 : i32 loc(#loc25)
+    %94 = ttg.async_wait %84, %86 {num = 2 : i32} loc(#loc23)
+    %95 = ttg.memdesc_subview %39[%93, %c0_i32, %c0_i32] : !ttg.memdesc<2x128x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xbf16, #shared, #smem, mutable, 2x128x64> loc(#loc23)
+    %96 = ttg.local_load %95 token %94 : !ttg.memdesc<128x64xbf16, #shared, #smem, mutable, 2x128x64> -> tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc23)
+    %97 = ttg.memdesc_subview %40[%93, %c0_i32, %c0_i32] : !ttg.memdesc<2x64x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
+    %98 = ttg.local_load %97 token %94 : !ttg.memdesc<64x64xbf16, #shared, #smem, mutable, 2x64x64> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc24)
+    %99 = tt.dot %96, %98, %81, inputPrecision = tf32 : tensor<128x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<128x64xf32, #mma> loc(#loc32)
+    %100 = arith.addi %82, %c1_i32 : i32 loc(#loc25)
+    %101 = arith.cmpi sge, %100, %c2_i32 : i32 loc(#loc25)
+    %102 = arith.select %101, %c0_i32, %100 : i32 loc(#loc25)
+    %103 = arith.addi %80, %c2_i32 : i32 loc(#loc25)
+    %104 = arith.muli %103, %c64_i32 : i32 loc(#loc33)
+    %105 = arith.subi %arg5, %104 : i32 loc(#loc28)
+    %106 = tt.splat %105 : i32 -> tensor<1x64xi32, #blocked> loc(#loc26)
+    %107 = arith.cmpi slt, %22, %106 : tensor<1x64xi32, #blocked> loc(#loc26)
+    %108 = tt.splat %104 : i32 -> tensor<128x64xi32, #blocked> loc(#loc29)
+    %109 = tt.addptr %25, %108 : tensor<128x64x!tt.ptr<bf16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc29)
+    %110 = tt.broadcast %107 : tensor<1x64xi1, #blocked> -> tensor<128x64xi1, #blocked> loc(#loc23)
+    %111 = ttg.memdesc_subview %39[%102, %c0_i32, %c0_i32] : !ttg.memdesc<2x128x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xbf16, #shared, #smem, mutable, 2x128x64> loc(#loc23)
+    %112 = tt.splat %90 : i1 -> tensor<128x64xi1, #blocked> loc(#loc25)
+    %113 = arith.andi %112, %110 : tensor<128x64xi1, #blocked> loc(#loc25)
+    %114 = ttg.async_copy_global_to_local %109, %111 mask %113 other %cst_0 : tensor<128x64x!tt.ptr<bf16>, #blocked> -> <128x64xbf16, #shared, #smem, mutable, 2x128x64> loc(#loc23)
+    %115 = ttg.async_commit_group %114 loc(#loc23)
+    %116 = tt.splat %105 : i32 -> tensor<64x1xi32, #blocked> loc(#loc27)
+    %117 = arith.cmpi slt, %27, %116 : tensor<64x1xi32, #blocked> loc(#loc27)
+    %118 = arith.muli %104, %arg7 : i32 loc(#loc30)
+    %119 = tt.splat %118 : i32 -> tensor<64x64xi32, #blocked> loc(#loc31)
+    %120 = tt.addptr %36, %119 : tensor<64x64x!tt.ptr<bf16>, #blocked>, tensor<64x64xi32, #blocked> loc(#loc31)
+    %121 = tt.broadcast %117 : tensor<64x1xi1, #blocked> -> tensor<64x64xi1, #blocked> loc(#loc24)
+    %122 = ttg.memdesc_subview %40[%102, %c0_i32, %c0_i32] : !ttg.memdesc<2x64x64xbf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
+    %123 = tt.splat %90 : i1 -> tensor<64x64xi1, #blocked> loc(#loc25)
+    %124 = arith.andi %123, %121 : tensor<64x64xi1, #blocked> loc(#loc25)
+    %125 = ttg.async_copy_global_to_local %120, %122 mask %124 other %cst_1 : tensor<64x64x!tt.ptr<bf16>, #blocked> -> <64x64xbf16, #shared, #smem, mutable, 2x64x64> loc(#loc24)
+    %126 = ttg.async_commit_group %125 loc(#loc24)
+    %127 = arith.addi %80, %c1_i32 : i32 loc(#loc25)
+    cf.br ^bb1(%127, %99, %102, %93, %85, %115, %87, %126 : i32, tensor<128x64xf32, #mma>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token) loc(#loc25)
+  ^bb3:  // pred: ^bb1
+    %128 = ttg.async_wait  {num = 0 : i32} loc(#loc25)
     ttg.local_dealloc %40 : !ttg.memdesc<2x64x64xbf16, #shared, #smem, mutable> loc(#loc25)
     ttg.local_dealloc %39 : !ttg.memdesc<2x128x64xbf16, #shared, #smem, mutable> loc(#loc25)
-    %82 = tt.splat %arg8 : i32 -> tensor<128x1xi32, #blocked1> loc(#loc34)
-    %83 = arith.muli %17, %82 : tensor<128x1xi32, #blocked1> loc(#loc34)
-    %84 = tt.splat %arg2 : !tt.ptr<f32> -> tensor<128x1x!tt.ptr<f32>, #blocked1> loc(#loc35)
-    %85 = tt.addptr %84, %83 : tensor<128x1x!tt.ptr<f32>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc35)
-    %86 = tt.broadcast %85 : tensor<128x1x!tt.ptr<f32>, #blocked1> -> tensor<128x64x!tt.ptr<f32>, #blocked1> loc(#loc36)
-    %87 = tt.broadcast %33 : tensor<1x64xi32, #blocked1> -> tensor<128x64xi32, #blocked1> loc(#loc36)
-    %88 = tt.addptr %86, %87 : tensor<128x64x!tt.ptr<f32>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc36)
-    %89 = tt.splat %arg3 : i32 -> tensor<128x1xi32, #blocked1> loc(#loc37)
-    %90 = arith.cmpi slt, %17, %89 : tensor<128x1xi32, #blocked1> loc(#loc37)
-    %91 = tt.splat %arg4 : i32 -> tensor<1x64xi32, #blocked1> loc(#loc38)
-    %92 = arith.cmpi slt, %33, %91 : tensor<1x64xi32, #blocked1> loc(#loc38)
-    %93 = tt.broadcast %90 : tensor<128x1xi1, #blocked1> -> tensor<128x64xi1, #blocked1> loc(#loc39)
-    %94 = tt.broadcast %92 : tensor<1x64xi1, #blocked1> -> tensor<128x64xi1, #blocked1> loc(#loc39)
-    %95 = arith.andi %93, %94 : tensor<128x64xi1, #blocked1> loc(#loc39)
-    %96 = ttg.convert_layout %80#0 : tensor<128x64xf32, #mma> -> tensor<128x64xf32, #blocked1> loc(#loc40)
-    tt.store %88, %96, %95 : tensor<128x64x!tt.ptr<f32>, #blocked1> loc(#loc40)
+    %129 = tt.splat %arg8 : i32 -> tensor<128x1xi32, #blocked1> loc(#loc34)
+    %130 = arith.muli %17, %129 : tensor<128x1xi32, #blocked1> loc(#loc34)
+    %131 = tt.splat %arg2 : !tt.ptr<f32> -> tensor<128x1x!tt.ptr<f32>, #blocked1> loc(#loc35)
+    %132 = tt.addptr %131, %130 : tensor<128x1x!tt.ptr<f32>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc35)
+    %133 = tt.broadcast %132 : tensor<128x1x!tt.ptr<f32>, #blocked1> -> tensor<128x64x!tt.ptr<f32>, #blocked1> loc(#loc36)
+    %134 = tt.broadcast %33 : tensor<1x64xi32, #blocked1> -> tensor<128x64xi32, #blocked1> loc(#loc36)
+    %135 = tt.addptr %133, %134 : tensor<128x64x!tt.ptr<f32>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc36)
+    %136 = tt.splat %arg3 : i32 -> tensor<128x1xi32, #blocked1> loc(#loc37)
+    %137 = arith.cmpi slt, %17, %136 : tensor<128x1xi32, #blocked1> loc(#loc37)
+    %138 = tt.splat %arg4 : i32 -> tensor<1x64xi32, #blocked1> loc(#loc38)
+    %139 = arith.cmpi slt, %33, %138 : tensor<1x64xi32, #blocked1> loc(#loc38)
+    %140 = tt.broadcast %137 : tensor<128x1xi1, #blocked1> -> tensor<128x64xi1, #blocked1> loc(#loc39)
+    %141 = tt.broadcast %139 : tensor<1x64xi1, #blocked1> -> tensor<128x64xi1, #blocked1> loc(#loc39)
+    %142 = arith.andi %140, %141 : tensor<128x64xi1, #blocked1> loc(#loc39)
+    %143 = ttg.convert_layout %81 : tensor<128x64xf32, #mma> -> tensor<128x64xf32, #blocked1> loc(#loc40)
+    tt.store %135, %143, %142 : tensor<128x64x!tt.ptr<f32>, #blocked1> loc(#loc40)
     tt.return loc(#loc41)
   } loc(#loc)
 } loc(#loc)
-#loc1 = loc(unknown)
 #loc2 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":18:26)
 #loc3 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":19:26)
 #loc4 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":21:21)
@@ -183,9 +191,6 @@
 #loc20 = loc("/workspace/Triton-blog-file/.venv/lib/python3.10/site-packages/triton/language/standard.py":40:22)
 #loc21 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":32:33)
 #loc22 = loc("/workspace/Triton-blog-file/.venv/lib/python3.10/site-packages/triton/language/standard.py":40:28)
-#loc23 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":35:20)
-#loc24 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":36:20)
-#loc25 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":32:22)
 #loc26 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":35:82)
 #loc27 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":36:82)
 #loc28 = loc("/workspace/Triton-blog-file/matmul/kernel/matmul-with-dot-bf16.py":33:22)
